{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5rfduRD1CSF"
      },
      "source": [
        "# Create your own private Copilot\n",
        "\n",
        "**In this guide I show you how to fine-tune Code Llama to become a private Copilot. For coding tasks, you can generally get much better performance out of Code Llama than Llama 2, especially when you specialise the model on a particular task:**\n",
        "\n",
        "- A Lora approach, quantizing the base model to int 8, freezing its weights and only training an adapter\n",
        "- Much of the code is refactored from [alpaca-lora](https://github.com/tloen/alpaca-lora).\n",
        "\n",
        "Avoid running this on V100 GPUs as it throws out errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lxQKE5MW310",
        "outputId": "6da0861f-4e3a-427d-94a9-9279fc91848d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (5.9.2)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat) (2.19.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat) (5.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat) (0.13.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat) (4.1.0)\n",
            "Collecting git+https://github.com/huggingface/transformers.git@main\n",
            "  Cloning https://github.com/huggingface/transformers.git (to revision main) to /tmp/pip-req-build-ggcxw3zx\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-ggcxw3zx\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 08a6e7a702d06826659eb7f0f6b9f37d33f31829\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.41.3.post2-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0.dev0) (2023.11.17)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.37.0.dev0-py3-none-any.whl size=8270030 sha256=668f2232e8c42e7df2f151292f83056707baa17148b7ad4dd78bf3b06dc4b17c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-o8st273v/wheels/cf/59/82/6492402e887a68975030bf8c06532260abc16abb7ccd8127cc\n",
            "Successfully built transformers\n",
            "Installing collected packages: bitsandbytes, transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "Successfully installed bitsandbytes-0.41.3.post2 transformers-4.37.0.dev0\n",
            "Collecting git+https://github.com/huggingface/peft.git@main\n",
            "  Cloning https://github.com/huggingface/peft.git (to revision main) to /tmp/pip-req-build-5gl4ty3i\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-5gl4ty3i\n",
            "  Resolved https://github.com/huggingface/peft.git to commit 482a2a6d9aaa01d534b1240e8c1ab6d346eb278f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (2.1.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (4.37.0.dev0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (4.66.1)\n",
            "Collecting accelerate>=0.21.0 (from peft==0.7.2.dev0)\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (0.4.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.7.2.dev0) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.7.2.dev0) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.7.2.dev0) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.7.2.dev0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.2.dev0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.2.dev0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.2.dev0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.2.dev0) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.7.2.dev0) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.7.2.dev0) (0.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft==0.7.2.dev0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.2.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.2.dev0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.2.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.2.dev0) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft==0.7.2.dev0) (1.3.0)\n",
            "Building wheels for collected packages: peft\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.7.2.dev0-py3-none-any.whl size=169030 sha256=f25e233e53598ef4fec7094c5df77992066d2a132dfa4bb586eece6b081e4767\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cxnql6sa/wheels/c4/e1/51/d197b9c452a772de94f87f5783e2cf47b87eb428a02cf30a0d\n",
            "Successfully built peft\n",
            "Installing collected packages: accelerate, peft\n",
            "Successfully installed accelerate-0.25.0 peft-0.7.2.dev0\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: pyarrow-hotfix, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.15.0 dill-0.3.7 multiprocess-0.70.15 pyarrow-hotfix-0.6\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.16.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.39.1-py2.py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.40 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.39.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.1\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "# Install python dependencies\n",
        "!pip install tqdm nbformat\n",
        "!pip install git+https://github.com/huggingface/transformers.git@main bitsandbytes\n",
        "!pip install git+https://github.com/huggingface/peft.git@main\n",
        "!pip install datasets\n",
        "import locale # colab workaround\n",
        "locale.getpreferredencoding = lambda x=False:\"UTF-8\" # colab workaround\n",
        "!pip install wandb\n",
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and install git-xet\n",
        "!curl -fsSLO https://github.com/xetdata/xet-tools/releases/latest/download/xet-linux-x86_64.tar.gz\n",
        "!tar -xvf xet-linux-x86_64.tar.gz && rm xet-linux-x86_64.tar.gz\n",
        "!mv git-xet /usr/local/bin\n",
        "!git xet install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJ-nvsLiXqU3",
        "outputId": "1b057dd3-c508-45d2-da8f-b53958e15f6c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "git-xet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0A5O9EwlW311"
      },
      "outputs": [],
      "source": [
        "# Set up authorization\n",
        "from IPython.display import clear_output\n",
        "user = input(\"GitHub user name?\")\n",
        "%env GH_USER=$user\n",
        "email = input(\"GitHub user email?\")\n",
        "%env GH_USER_EMAIL=$email\n",
        "token = input(\"GitHub token?\")\n",
        "%env GH_TOKEN=$token\n",
        "repo = input(\"GitHub model repo?\")\n",
        "%env MODEL_REPO=$repo\n",
        "%env XET_LOG_PATH=log.txt\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name $GH_USER\n",
        "!git config --global user.email $GH_USER_EMAIL"
      ],
      "metadata": {
        "id": "Q-rjZRSXX4X3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clones the model repo\n",
        "!git xet clone --lazy https://$GH_USER:$GH_TOKEN@github.com/$GH_USER/$MODEL_REPO.git -- --branch colab\n",
        "!cd LLM_fine_tuning && git xet materialize CodeLlama-7b-hf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vs7NWkwmXKXE",
        "outputId": "9559a3b3-037a-4782-ec84-3f99755e6f81"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing to clone Xet repository.\n",
            "Cloning into 'LLM_fine_tuning'...\n",
            "remote: Enumerating objects: 70, done.\u001b[K\n",
            "remote: Counting objects: 100% (70/70), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 70 (delta 19), reused 41 (delta 8), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (70/70), 60.72 KiB | 5.06 MiB/s, done.\n",
            "Resolving deltas: 100% (19/19), done.\n",
            "git-xet 0.12.7 filter started\n",
            "Updating files: 100% (20/20), done.\n",
            "Materializing 12 file(s)...\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXXSZVwKW311",
        "outputId": "19cec276-91ae-455d-bc10-cf5ec48e0abd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total file paths: 320.\n",
            "Reading file contents...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:00<00:00, 1711.23it/s]\n"
          ]
        }
      ],
      "source": [
        "# Get training dataset\n",
        "from LLM_fine_tuning.scripts.prepare_dataset import create_dataset_from_git_repo\n",
        "username='xetdata'\n",
        "repository='xet-core'\n",
        "parquet_file = create_dataset_from_git_repo(username,repository)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "3tvZaQ7fW312",
        "outputId": "30001c1c-1a28-423c-b710-442878ebcfd4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      repo_id                                          file_path  \\\n",
              "0    xet-core                                   xet-core/LICENSE   \n",
              "1    xet-core                                 xet-core/README.md   \n",
              "2    xet-core                           xet-core/rust/Cargo.toml   \n",
              "3    xet-core                 xet-core/rust/cas_client/README.md   \n",
              "4    xet-core                xet-core/rust/cas_client/Dockerfile   \n",
              "..        ...                                                ...   \n",
              "315  xet-core  xet-core/rust/gitxet/scripts/tests/create_test...   \n",
              "316  xet-core  xet-core/rust/gitxet/scripts/tests/test_01_pus...   \n",
              "317  xet-core   xet-core/rust/prometheus_dict_encoder/Cargo.toml   \n",
              "318  xet-core   xet-core/rust/prometheus_dict_encoder/src/lib.rs   \n",
              "319  xet-core                      xet-core/.circleci/config.yml   \n",
              "\n",
              "                                               content  \n",
              "0    BSD 3-Clause License\\n\\nCopyright (c) 2023, Xe...  \n",
              "1    <p align=\"center\">\\n   <img src=\"https://githu...  \n",
              "2    [workspace]\\n\\nmembers = [\\n    \"libmagic\",\\n ...  \n",
              "3    # CAS client \\nUtilities to wrap around the gr...  \n",
              "4    FROM rust:1.58 as builder\\n\\nRUN USER=root rus...  \n",
              "..                                                 ...  \n",
              "315  #!/usr/bin/env bash\\nset -e\\nset -x\\n\\nif [[ $...  \n",
              "316  #!/usr/bin/env bash\\nset -e\\nset -x\\n\\nscript_...  \n",
              "317  [package]\\nname = \"prometheus_dict_encoder\"\\nv...  \n",
              "318  use prometheus::proto;\\nuse prometheus::proto:...  \n",
              "319  version: 2.1\\n\\norbs:\\n  slack: circleci/slack...  \n",
              "\n",
              "[320 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8a6454c-b2e3-46db-ae42-597051b27948\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>repo_id</th>\n",
              "      <th>file_path</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xet-core</td>\n",
              "      <td>xet-core/LICENSE</td>\n",
              "      <td>BSD 3-Clause License\\n\\nCopyright (c) 2023, Xe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xet-core</td>\n",
              "      <td>xet-core/README.md</td>\n",
              "      <td>&lt;p align=\"center\"&gt;\\n   &lt;img src=\"https://githu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>xet-core</td>\n",
              "      <td>xet-core/rust/Cargo.toml</td>\n",
              "      <td>[workspace]\\n\\nmembers = [\\n    \"libmagic\",\\n ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>xet-core</td>\n",
              "      <td>xet-core/rust/cas_client/README.md</td>\n",
              "      <td># CAS client \\nUtilities to wrap around the gr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>xet-core</td>\n",
              "      <td>xet-core/rust/cas_client/Dockerfile</td>\n",
              "      <td>FROM rust:1.58 as builder\\n\\nRUN USER=root rus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315</th>\n",
              "      <td>xet-core</td>\n",
              "      <td>xet-core/rust/gitxet/scripts/tests/create_test...</td>\n",
              "      <td>#!/usr/bin/env bash\\nset -e\\nset -x\\n\\nif [[ $...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316</th>\n",
              "      <td>xet-core</td>\n",
              "      <td>xet-core/rust/gitxet/scripts/tests/test_01_pus...</td>\n",
              "      <td>#!/usr/bin/env bash\\nset -e\\nset -x\\n\\nscript_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317</th>\n",
              "      <td>xet-core</td>\n",
              "      <td>xet-core/rust/prometheus_dict_encoder/Cargo.toml</td>\n",
              "      <td>[package]\\nname = \"prometheus_dict_encoder\"\\nv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>xet-core</td>\n",
              "      <td>xet-core/rust/prometheus_dict_encoder/src/lib.rs</td>\n",
              "      <td>use prometheus::proto;\\nuse prometheus::proto:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>xet-core</td>\n",
              "      <td>xet-core/.circleci/config.yml</td>\n",
              "      <td>version: 2.1\\n\\norbs:\\n  slack: circleci/slack...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>320 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8a6454c-b2e3-46db-ae42-597051b27948')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a8a6454c-b2e3-46db-ae42-597051b27948 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a8a6454c-b2e3-46db-ae42-597051b27948');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ae311ab0-e49d-460d-bb6b-01fb252ddf8a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ae311ab0-e49d-460d-bb6b-01fb252ddf8a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ae311ab0-e49d-460d-bb6b-01fb252ddf8a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_38dc69e4-063c-4ed5-b3ec-0aa46eabb364\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_38dc69e4-063c-4ed5-b3ec-0aa46eabb364 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_parquet(parquet_file)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mu9JczX1CSH"
      },
      "source": [
        "### Loading libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oTeYW8z51CSH",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    get_peft_model_state_dict,\n",
        "    prepare_model_for_int8_training,\n",
        "    set_peft_model_state_dict,\n",
        ")\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32zH9-hM1CSH"
      },
      "source": [
        "(If you have import errors, try restarting your Jupyter kernel)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M9KyT0S1CSH"
      },
      "source": [
        "### Load dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "w44O1EK-1CSH",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset, load_dataset\n",
        "dataset = Dataset.from_pandas(df, split=\"train\")\n",
        "train_dataset = dataset.train_test_split(test_size=0.1)[\"train\"]\n",
        "eval_dataset = dataset.train_test_split(test_size=0.1)[\"test\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJ54EffO1CSI"
      },
      "source": [
        "The above pulls the dataset from the Huggingface Hub and splits 10% of it into an evaluation set to check how well the model is doing through training. If you want to load your own dataset do this:\n",
        "\n",
        "```\n",
        "train_dataset = load_dataset('json', data_files='train_set.jsonl', split='train')\n",
        "eval_dataset = load_dataset('json', data_files='validation_set.jsonl', split='train')\n",
        "```\n",
        "\n",
        "And if you want to view any samples in the dataset just do something like:``` ```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFbeaZzf1CSJ",
        "outputId": "ee071120-5566-4106-d3b8-84c10bc2fecb",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'repo_id': 'xet-core', 'file_path': 'xet-core/rust/gitxetcore/src/constants.rs', 'content': '// TODO: .git is not reliably the git subfolder; need to use the proper version.\\npub const CAS_STAGING_SUBDIR: &str = \"xet/staging\";\\npub const GIT_NOTES_MERKLEDB_V1_REF_SUFFIX: &str = \"xet/merkledb\";\\npub const GIT_NOTES_MERKLEDB_V1_REF_NAME: &str = \"refs/notes/xet/merkledb\";\\npub const GIT_NOTES_SUMMARIES_REF_SUFFIX: &str = \"xet/summaries\";\\npub const GIT_NOTES_SUMMARIES_REF_NAME: &str = \"refs/notes/xet/summaries\";\\npub const MERKLEDBV1_PATH_SUBDIR: &str = \"xet/merkledb.db\";\\npub const SUMMARIES_PATH_SUBDIR: &str = \"xet/summaries.db\";\\n\\npub const GIT_NOTES_MERKLEDB_V2_REF_SUFFIX: &str = \"xet/merkledbv2\";\\npub const GIT_NOTES_MERKLEDB_V2_REF_NAME: &str = \"refs/notes/xet/merkledbv2\";\\npub const MERKLEDB_V2_CACHE_PATH_SUBDIR: &str = \"xet/merkledbv2-cache\";\\npub const MERKLEDB_V2_SESSION_PATH_SUBDIR: &str = \"xet/merkledbv2-session\";\\n\\npub const GIT_NOTES_REPO_SALT_REF_SUFFIX: &str = \"xet/reposalt\";\\npub const GIT_NOTES_REPO_SALT_REF_NAME: &str = \"refs/notes/xet/reposalt\";\\n\\npub const GIT_LAZY_CHECKOUT_CONFIG: &str = \"xet/lazyconfig\";\\n\\n// This file is checked into the repo.  Path is relative to the repo root.\\npub const GIT_REPO_SPECIFIC_CONFIG: &str = \".xet/config.toml\";\\n\\n/// The maximum git filter protocol packet size\\npub const GIT_MAX_PACKET_SIZE: usize = 65516;\\n\\n/// We put a limit on the pointer file size so that\\n/// we don\\'t ever try to read a whole giant blob into memory when\\n/// trying to clean. The maximum git packet size is 65516.\\n/// By setting this threshold to 65515, we can ensure that reading exactly\\n/// 1 packet is enough to determine if it is a valid pointer file.\\npub const POINTER_FILE_LIMIT: usize = GIT_MAX_PACKET_SIZE - 1;\\n\\n/// If a file has size smaller than this threshold, AND if it \"looks-like\"\\n/// text, we interpret this as a text file and passthrough the file, letting\\n/// git handle it. See `small_file_determination.rs` for details.\\n///\\n/// We set this to be 1 less than a constant multiple of the GIT_MAX_PACKET_SIZE\\n/// so we can read exactly up to that multiple of packets to determine if it\\n/// is a small file.\\npub const SMALL_FILE_THRESHOLD: usize = 4 * GIT_MAX_PACKET_SIZE - 1;\\n\\n/// The maximum number of simultaneous download streams\\npub const MAX_CONCURRENT_DOWNLOADS: usize = 16;\\n/// The maximum number of simultaneous upload streams\\npub const MAX_CONCURRENT_UPLOADS: usize = 16;\\n\\n/// The maximum number of simultaneous streams per prefetch call\\npub const MAX_CONCURRENT_PREFETCH_DOWNLOADS: usize = 4;\\n/// The maximum number of simultaneous prefetches\\npub const MAX_CONCURRENT_PREFETCHES: usize = 4;\\n/// This is the amount to download per prefetch\\npub const PREFETCH_WINDOW_SIZE_BYTES: u64 = 32 * 1024 * 1024;\\n/// Number of historical prefetches to track\\npub const PREFETCH_TRACK_COUNT: usize = 32;\\n\\n/// Number of block derivations to memoize\\npub const DERIVE_BLOCKS_CACHE_COUNT: usize = 512;\\n\\n/// scheme for a local filesystem based CAS server\\npub const LOCAL_CAS_SCHEME: &str = \"local://\";\\n\\n/// The allowed endupoints usable with xet svc.\\npub const XET_ALLOWED_ENDPOINTS: &[&str] = &[\"xethub.com\", \"xetsvc.com\", \"xetbeta.com\"];\\n\\n/// The minimum git version compatible with git xet.\\npub const MINIMUM_GIT_VERSION: &str = \"2.29\";\\n\\n/// The current version\\npub const CURRENT_VERSION: &str = env!(\"CARGO_PKG_VERSION\");\\n\\n/// Maximum number of entries in the file construction cache\\n/// which stores File Hash -> reconstruction instructions\\npub const FILE_RECONSTRUCTION_CACHE_SIZE: usize = 65536;\\n\\n// Salt is 256-bit in length.\\npub const REPO_SALT_LEN: usize = 32;\\n'}\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xb42Xar6W313",
        "outputId": "b45032c1-d2ff-4fd3-b987-e1d286ebe0aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'repo_id': 'xet-core', 'file_path': 'xet-core/rust/cas_client/src/caching_client.rs', 'content': 'use crate::client_adapter::ClientRemoteAdapter;\\nuse crate::interface::{CasClientError, Client};\\nuse anyhow::anyhow;\\nuse async_trait::async_trait;\\nuse cache::{CacheError, Remote, XorbCache};\\nuse cas::key::Key;\\nuse merklehash::MerkleHash;\\nuse std::collections::HashMap;\\nuse std::fmt::Debug;\\nuse std::ops::Range;\\nuse std::path::Path;\\nuse std::sync::{Arc, Mutex};\\nuse tracing::{debug, info, warn};\\n\\n#[derive(Debug)]\\npub struct CachingClient<T: Client + Debug + Sync + Send + \\'static> {\\n    client: Arc<T>,\\n    cache: Arc<dyn XorbCache>,\\n    xorb_lengths: Arc<Mutex<HashMap<MerkleHash, u64>>>,\\n}\\n\\nimpl<T: Client + Debug + Sync + Send + \\'static> CachingClient<T> {\\n    /// Create a new caching client.\\n    /// client: This is the client object used to satisfy requests\\n    pub fn new(\\n        client: T,\\n        cache_path: &Path,\\n        capacity_bytes: u64,\\n        blocksize: Option<u64>,\\n    ) -> Result<CachingClient<T>, anyhow::Error> {\\n        // convert Path to String\\n        let canonical_path = cache_path.canonicalize().map_err(|e| {\\n            anyhow::Error::from(e)\\n                .context(format!(\"Unable to canonicalize cache path {cache_path:?}\"))\\n        })?;\\n        let canonical_string_path = canonical_path.to_str().ok_or_else(|| {\\n            anyhow!(\\n                \"Unable to convert path to utf-8 string {:?}\",\\n                canonical_path\\n            )\\n        })?;\\n        let arcclient = Arc::new(client);\\n        let client_remote_arc: Arc<dyn Remote> =\\n            Arc::new(ClientRemoteAdapter::new(arcclient.clone()));\\n\\n        info!(\\n            \"Creating CachingClient {:?} with capacity {} blocksize {:?}\",\\n            cache_path, capacity_bytes, blocksize\\n        );\\n\\n        let cache = cache::from_config(\\n            cache::CacheConfig {\\n                cache_dir: canonical_string_path.to_string(),\\n                capacity: capacity_bytes,\\n                block_size: blocksize.unwrap_or(16 * 1024 * 1024),\\n            },\\n            client_remote_arc,\\n        )\\n        .map_err(|e| {\\n            warn!(\"Error creating caching client\");\\n            anyhow::Error::from(e).context(\"Error while creating caching client\")\\n        })?;\\n\\n        Ok(CachingClient {\\n            client: arcclient,\\n            cache,\\n            xorb_lengths: Arc::new(Mutex::new(HashMap::new())),\\n        })\\n    }\\n}\\n\\n#[async_trait]\\nimpl<T: Client + Debug + Sync + Send> Client for CachingClient<T> {\\n    async fn put(\\n        &self,\\n        prefix: &str,\\n        hash: &MerkleHash,\\n        data: Vec<u8>,\\n        chunk_boundaries: Vec<u64>,\\n    ) -> Result<(), CasClientError> {\\n        // puts write through\\n        debug!(\\n            \"CachingClient put to {}/{} of length {} bytes\",\\n            prefix,\\n            hash,\\n            data.len()\\n        );\\n        self.client.put(prefix, hash, data, chunk_boundaries).await\\n    }\\n\\n    async fn flush(&self) -> Result<(), CasClientError> {\\n        // forward flush to the underlying client\\n        self.client.flush().await\\n    }\\n\\n    async fn get(&self, prefix: &str, hash: &MerkleHash) -> Result<Vec<u8>, CasClientError> {\\n        // get the length, reduce to range read of the entire length.\\n        debug!(\"CachingClient Get of {}/{}\", prefix, hash);\\n        let xorb_size = match self.get_length(prefix, hash).await {\\n            Err(e) => {\\n                debug!(\"CachingClient Get: get_length reported error : {e:?}\");\\n                return Err(e);\\n            }\\n            Ok(v) => {\\n                debug!(\"CachingClient Get: get_length call succeeded with value {v}.\");\\n                v\\n            }\\n        };\\n\\n        self.get_object_range(prefix, hash, vec![(0, xorb_size)])\\n            .await\\n            .map(|mut v| v.swap_remove(0))\\n    }\\n\\n    async fn get_object_range(\\n        &self,\\n        prefix: &str,\\n        hash: &MerkleHash,\\n        ranges: Vec<(u64, u64)>,\\n    ) -> Result<Vec<Vec<u8>>, CasClientError> {\\n        debug!(\\n            \"CachingClient GetObjectRange of {}/{}: {:?}\",\\n            prefix, hash, ranges\\n        );\\n        let mut ret: Vec<Vec<u8>> = Vec::new();\\n        for (start, end) in ranges {\\n            let prefix_str = prefix.to_string();\\n            ret.push(\\n                self.cache\\n                    .fetch_xorb_range(\\n                        &Key {\\n                            prefix: prefix_str,\\n                            hash: *hash,\\n                        },\\n                        Range { start, end },\\n                        None,\\n                    )\\n                    .await\\n                    .map_err(|e| {\\n                        warn!(\\n                            \"CachingClient Error on GetObjectRange of {}/{}: {:?}\",\\n                            prefix, hash, e\\n                        );\\n                        match e {\\n                            CacheError::InvalidRange(_, _) => CasClientError::InvalidRange,\\n                            CacheError::RemoteError(e) => CasClientError::Grpc(e),\\n                            e => CasClientError::InternalError(anyhow::Error::from(e).context(\\n                                format!(\\n                                    \"Fail on get object range of {:?} {:?} range {:?}\",\\n                                    prefix,\\n                                    hash,\\n                                    (start, end)\\n                                ),\\n                            )),\\n                        }\\n                    })?,\\n            )\\n        }\\n        Ok(ret)\\n    }\\n\\n    async fn get_length(&self, prefix: &str, hash: &MerkleHash) -> Result<u64, CasClientError> {\\n        debug!(\"CachingClient GetLength of {}/{}\", prefix, hash);\\n        {\\n            // check the xorb length cache\\n            let xorb_lengths = self.xorb_lengths.lock().unwrap();\\n            if let Some(l) = xorb_lengths.get(hash) {\\n                return Ok(*l);\\n            }\\n            // release lock here since get_length may take a while\\n        }\\n        let ret = self.client.get_length(prefix, hash).await;\\n\\n        if let Ok(l) = ret {\\n            // insert it into the xorb length cache\\n            let mut xorb_lengths = self.xorb_lengths.lock().unwrap();\\n            xorb_lengths.insert(*hash, l);\\n        }\\n        ret\\n    }\\n}\\n\\n#[cfg(test)]\\nmod tests {\\n    use crate::*;\\n    use std::fs;\\n    use std::path::Path;\\n    use std::sync::Arc;\\n    use tempfile::TempDir;\\n\\n    fn path_has_files(path: &Path) -> bool {\\n        fs::read_dir(path).unwrap().count() > 0\\n    }\\n\\n    #[tokio::test]\\n    async fn test_basic_read_write() {\\n        let client = Arc::new(LocalClient::default());\\n        let cachedir = TempDir::new().unwrap();\\n        assert!(!path_has_files(cachedir.path()));\\n\\n        let client = CachingClient::new(client, cachedir.path(), 100, None).unwrap();\\n\\n        // the root hash of a single chunk is just the hash of the data\\n        let hello = \"hello world\".as_bytes().to_vec();\\n        let hello_hash = merklehash::compute_data_hash(&hello[..]);\\n        // write \"hello world\"\\n        client\\n            .put(\"key\", &hello_hash, hello.clone(), vec![hello.len() as u64])\\n            .await\\n            .unwrap();\\n\\n        // get length \"hello world\"\\n        assert_eq!(11, client.get_length(\"key\", &hello_hash).await.unwrap());\\n\\n        // read \"hello world\"\\n        assert_eq!(hello, client.get(\"key\", &hello_hash).await.unwrap());\\n\\n        // read range \"hello\" and \"world\"\\n        let ranges_to_read: Vec<(u64, u64)> = vec![(0, 5), (6, 11)];\\n        let expected: Vec<Vec<u8>> = vec![\"hello\".as_bytes().to_vec(), \"world\".as_bytes().to_vec()];\\n        assert_eq!(\\n            expected,\\n            client\\n                .get_object_range(\"key\", &hello_hash, ranges_to_read)\\n                .await\\n                .unwrap()\\n        );\\n        // read range \"hello\" and \"world\", with truncation for larger offsets\\n        let ranges_to_read: Vec<(u64, u64)> = vec![(0, 5), (6, 20)];\\n        let expected: Vec<Vec<u8>> = vec![\"hello\".as_bytes().to_vec(), \"world\".as_bytes().to_vec()];\\n        assert_eq!(\\n            expected,\\n            client\\n                .get_object_range(\"key\", &hello_hash, ranges_to_read)\\n                .await\\n                .unwrap()\\n        );\\n        // empty read\\n        let ranges_to_read: Vec<(u64, u64)> = vec![(0, 5), (6, 6)];\\n        let expected: Vec<Vec<u8>> = vec![\"hello\".as_bytes().to_vec(), \"\".as_bytes().to_vec()];\\n        assert_eq!(\\n            expected,\\n            client\\n                .get_object_range(\"key\", &hello_hash, ranges_to_read)\\n                .await\\n                .unwrap()\\n        );\\n        assert!(path_has_files(cachedir.path()));\\n    }\\n\\n    #[tokio::test]\\n    async fn test_failures() {\\n        let client = Arc::new(LocalClient::default());\\n        let cachedir = TempDir::new().unwrap();\\n        assert!(!path_has_files(cachedir.path()));\\n\\n        let client = CachingClient::new(client, cachedir.path(), 100, None).unwrap();\\n\\n        let hello = \"hello world\".as_bytes().to_vec();\\n        let hello_hash = merklehash::compute_data_hash(&hello[..]);\\n        // write \"hello world\"\\n        client\\n            .put(\"key\", &hello_hash, hello.clone(), vec![hello.len() as u64])\\n            .await\\n            .unwrap();\\n        // put the same value a second time. This should be ok.\\n        client\\n            .put(\"key\", &hello_hash, hello.clone(), vec![hello.len() as u64])\\n            .await\\n            .unwrap();\\n\\n        // put the different value with the same hash\\n        // this should fail\\n        assert_eq!(\\n            CasClientError::HashMismatch,\\n            client\\n                .put(\\n                    \"key\",\\n                    &hello_hash,\\n                    \"hellp world\".as_bytes().to_vec(),\\n                    vec![hello.len() as u64],\\n                )\\n                .await\\n                .unwrap_err()\\n        );\\n        // content shorter than the chunk boundaries should fail\\n        assert_eq!(\\n            CasClientError::InvalidArguments,\\n            client\\n                .put(\\n                    \"key\",\\n                    &hello_hash,\\n                    \"hellp wod\".as_bytes().to_vec(),\\n                    vec![hello.len() as u64],\\n                )\\n                .await\\n                .unwrap_err()\\n        );\\n\\n        // content longer than the chunk boundaries should fail\\n        assert_eq!(\\n            CasClientError::InvalidArguments,\\n            client\\n                .put(\\n                    \"key\",\\n                    &hello_hash,\\n                    \"hello world again\".as_bytes().to_vec(),\\n                    vec![hello.len() as u64],\\n                )\\n                .await\\n                .unwrap_err()\\n        );\\n\\n        // empty writes should fail\\n        assert_eq!(\\n            CasClientError::InvalidArguments,\\n            client\\n                .put(\"key\", &hello_hash, vec![], vec![],)\\n                .await\\n                .unwrap_err()\\n        );\\n\\n        // compute a hash of something we do not have in the store\\n        let world = \"world\".as_bytes().to_vec();\\n        let world_hash = merklehash::compute_data_hash(&world[..]);\\n\\n        // get length of non-existant object should fail with XORBNotFound\\n        assert_eq!(\\n            CasClientError::XORBNotFound(world_hash),\\n            client.get_length(\"key\", &world_hash).await.unwrap_err()\\n        );\\n\\n        // read of non-existant object should fail with XORBNotFound\\n        assert_eq!(\\n            CasClientError::XORBNotFound(world_hash),\\n            client.get(\"key\", &world_hash).await.unwrap_err()\\n        );\\n        // read range of non-existant object should fail with XORBNotFound\\n        assert!(client\\n            .get_object_range(\"key\", &world_hash, vec![(0, 5)])\\n            .await\\n            .is_err());\\n    }\\n}\\n'}\n"
          ]
        }
      ],
      "source": [
        "print(eval_dataset[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHdMYcu61CSJ"
      },
      "source": [
        "Each entry is made up of a text 'question', the sql table 'context' and the 'answer'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ig7NvWN1CSJ"
      },
      "source": [
        "### Load model\n",
        "I load code llama from huggingface in int8. Standard for Lora:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ccfdb5b3eab542f99038e3b850902ad8",
            "6b49e9ef3eb3400d9d413e4691158147",
            "c746af61c6fd4e9aa0e8f3a8922c07f5",
            "2bedb7a3425e41e0a8476cfa71b309b2",
            "fd03926d82434e82875544ddc0e0fa68",
            "cba1a51f406c4641a89dd2803a443ed0",
            "08d5b480eaf1400bad50e3f85db54f9e",
            "390c417ab953485cbeaef685b963924c",
            "06aa7ea6f81b4403b902ebd381fa8178",
            "5ce401bf4e8d42a6bed2554641d7fce5",
            "b71f0b968f6a4a7ca0132d30328f6491"
          ]
        },
        "id": "rMnU93bY1CSJ",
        "outputId": "3345a7dc-d66e-44f3-a0c8-a52d6ee68b0e",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ccfdb5b3eab542f99038e3b850902ad8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "base_model = \"./LLM_fine_tuning/CodeLlama-7b-hf\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model,\n",
        "    load_in_8bit=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3OF-wtj1CSJ"
      },
      "source": [
        "torch_dtype=torch.float16 means computations are performed using a float16 representation, even though the values themselves are 8 bit ints.\n",
        "\n",
        "If you get error \"ValueError: Tokenizer class CodeLlamaTokenizer does not exist or is not currently imported.\" Make sure you have transformers version is 4.33.0.dev0 and accelerate is >=0.20.3.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2VXqJJe1CSJ"
      },
      "source": [
        "### 3. Check base model\n",
        "A very good common practice is to check whether a model can already do the task at hand. Fine-tuning is something you want to try to avoid at all cost:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uiyAff1a1CSJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c64ad368-393f-47e9-f003-6443782a7853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a powerful code generation model. Your job is to complete the below Rust function.\n",
            "/// Walk the repo working directory starting from search_root.\n",
            "/// Return a list of file paths under the search_root, the\n",
            "/// file paths are relative to the working dir root.\n",
            "/// Note that symlinks are ignored because they are difficult to\n",
            "/// deal with: git deals with the symlink file itself without\n",
            "/// following the link.\n",
            "pub fn walk_working_dir(\n",
            "    work_root: impl AsRef<Path>,\n",
            "    search_root: impl AsRef<Path>,\n",
            "    recursive: bool,\n",
            ") -> anyhow::Result<Vec<PathBuf>> {\n",
            "  \n",
            "  \n",
            "  Ok(result)\n",
            "}\n",
            "let work_root = work_root.as_ref();\n",
            "  let search_root = search_root.as_ref();\n",
            "  let mut result = Vec::new();\n",
            "  let mut stack = Vec::new();\n",
            "  stack.push(search_root);\n",
            "  while let Some(path) = stack.pop() {\n",
            "    let mut entries = fs::read_dir(path)?;\n",
            "    while let Some(entry) = entries.next()\n"
          ]
        }
      ],
      "source": [
        "eval_prompt = \"\"\"You are a powerful code generation model. Your job is to complete the below Rust function.\n",
        "/// Walk the repo working directory starting from search_root.\n",
        "/// Return a list of file paths under the search_root, the\n",
        "/// file paths are relative to the working dir root.\n",
        "/// Note that symlinks are ignored because they are difficult to\n",
        "/// deal with: git deals with the symlink file itself without\n",
        "/// following the link.\n",
        "pub fn walk_working_dir(\n",
        "    work_root: impl AsRef<Path>,\n",
        "    search_root: impl AsRef<Path>,\n",
        "    recursive: bool,\n",
        ") -> anyhow::Result<Vec<PathBuf>> {\n",
        "  <FILL_ME>\n",
        "\n",
        "  Ok(result)\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=100)[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "544rmsdU1CSJ"
      },
      "source": [
        "I get the output:\n",
        "```\n",
        "llet work_root = work_root.as_ref();\n",
        "  let search_root = search_root.as_ref();\n",
        "  let mut result = Vec::new();\n",
        "  let mut stack = Vec::new();\n",
        "  stack.push(search_root.to_path_buf());\n",
        "  while let Some(path) = stack.pop() {\n",
        "    if path.starts_with(work_root) {\n",
        "      for entry in path.read\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puuOXL2R1CSJ"
      },
      "source": [
        "### 4. Tokenization\n",
        "Setup some tokenization settings like left padding because it makes [training use less memory](https://ai.stackexchange.com/questions/41485/while-fine-tuning-a-decoder-only-llm-like-llama-on-chat-dataset-what-kind-of-pa):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "c1P0mphA1CSJ"
      },
      "outputs": [],
      "source": [
        "tokenizer.add_eos_token = True\n",
        "tokenizer.pad_token_id = 0\n",
        "tokenizer.padding_side = \"left\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpo66hMo1CSJ"
      },
      "source": [
        "Setup the tokenize function to make labels and input_ids the same. This is basically what [self-supervised fine-tuning](https://neptune.ai/blog/self-supervised-learning) is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gjSerml71CSJ"
      },
      "outputs": [],
      "source": [
        "def tokenize(prompt):\n",
        "    result = tokenizer(\n",
        "        prompt,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding=False,\n",
        "        return_tensors=None,\n",
        "    )\n",
        "\n",
        "    # \"self-supervised learning\" means the labels are also the inputs:\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MvO7A-ZF1CSK"
      },
      "outputs": [],
      "source": [
        "def generate_and_tokenize_prompt(data_point):\n",
        "    full_prompt =f\"\"\"\n",
        "    ### Repository:\n",
        "    {data_point[\"repo_id\"]}\n",
        "\n",
        "    ### File Path:\n",
        "    {data_point[\"file_path\"]}\n",
        "\n",
        "    ### Source Code:\n",
        "    {data_point[\"content\"]}\n",
        "    \"\"\"\n",
        "    return tokenize(full_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLvwo-ax1CSK"
      },
      "source": [
        "Reformat to prompt and tokenize each sample:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SA2BqSzW1CSK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "96487863814d486bba165b4ea7d57c93",
            "9153ffc8d412470695671ae4a7b5bc0c",
            "f2d64744eac348798011a02b78c195b6",
            "ac0fe69dcad94153802cbd1240fc7cb7",
            "cf67d535aa904052b2129b4485ef2589",
            "ac88bc629fc24c19affc3ca8a77d9101",
            "2033e63cb81649c5a5565b674d6561a2",
            "c64a8d2ad2554571ac81d0b2245282bc",
            "2503e46973644ce0bcc9d1cd3cf90a16",
            "efdddef709bd448294b413b20973ce94",
            "5721b429cdbe4a4fabfb4e266d0a5b8a",
            "10fed5bf8ff34b20943bb858fde7451e",
            "85c6b5d3ed4046b3a30ac675ba36908b",
            "aab05682cf204c828f55e03fca4b7a3a",
            "bf2578d5c6ec4299936e678447f46c69",
            "e9c99387b0914bfdaad0fab70ec5f580",
            "412309cc0a224be5b51a54d88d74c492",
            "30386ef794ec43a1ae06688a1ffbb0f2",
            "09a769a9822a42f7ae2664a1d80a8905",
            "c039af9f6b4d4fefb074b7da2566174c",
            "2b8c59b0b94049e298ec744f9894981a",
            "e37154250e974e1e880f85da0665e5e8"
          ]
        },
        "outputId": "1803352e-4be8-4569-fd96-1df08a515ec1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/288 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96487863814d486bba165b4ea7d57c93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/32 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10fed5bf8ff34b20943bb858fde7451e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
        "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5ByhitV1CSK"
      },
      "source": [
        "### 5. Setup Lora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9q_26pz71CSK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fb1f830-135b-49c2-d9dc-c67e63c3b6e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:143: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model.train() # put model back into training mode\n",
        "model = prepare_model_for_int8_training(model)\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\n",
        "    \"q_proj\",\n",
        "    \"k_proj\",\n",
        "    \"v_proj\",\n",
        "    \"o_proj\",\n",
        "],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "model = get_peft_model(model, config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GW1wtvbP1CSK"
      },
      "source": [
        "Optional stuff to setup Weights and Biases to view training graphs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AC1_qWbS1CSK"
      },
      "outputs": [],
      "source": [
        "wandb_project = \"\"\n",
        "if len(wandb_project) > 0:\n",
        "    os.environ[\"WANDB_PROJECT\"] = wandb_project\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "5iv4txxu1CSK"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.device_count() > 1:\n",
        "    # keeps Trainer from trying its own DataParallelism when more than 1 gpu is available\n",
        "    model.is_parallelizable = True\n",
        "    model.model_parallel = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYSsnciQ1CSK"
      },
      "source": [
        "### 6. Training arguments\n",
        "If you run out of GPU memory, change per_device_train_batch_size. The gradient_accumulation_steps variable should ensure this doesn't affect batch dynamics during the training run. All the other variables are standard stuff that I wouldn't recommend messing with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "uvEi1kP21CSK"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "per_device_train_batch_size = 8\n",
        "gradient_accumulation_steps = batch_size // per_device_train_batch_size\n",
        "output_dir = \"code-llama\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "        per_device_train_batch_size=per_device_train_batch_size,\n",
        "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "        warmup_steps=100,\n",
        "        max_steps=400,\n",
        "        learning_rate=3e-4,\n",
        "        fp16=True,\n",
        "        logging_steps=10,\n",
        "        optim=\"adamw_torch\",\n",
        "        evaluation_strategy=\"steps\", # if val_set_size > 0 else \"no\",\n",
        "        save_strategy=\"steps\",\n",
        "        eval_steps=20,\n",
        "        save_steps=20,\n",
        "        output_dir=output_dir,\n",
        "        # save_total_limit=3,\n",
        "        load_best_model_at_end=False,\n",
        "        # ddp_find_unused_parameters=False if ddp else None,\n",
        "        group_by_length=True, # group sequences of roughly the same length together to speed up training\n",
        "        report_to=\"none\", # if use_wandb else \"none\",\n",
        "        run_name=f\"codellama-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\", # if use_wandb else None,\n",
        "    )\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_val_dataset,\n",
        "    args=training_args,\n",
        "    data_collator=DataCollatorForSeq2Seq(\n",
        "        tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aJp6Jxl1CSK"
      },
      "source": [
        "Then we do some pytorch-related optimisation (which just make training faster but don't affect accuracy):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6ycCHZZl1CSK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab1fd00-2639-49d4-87b6-45a372bd3830"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compiling the model\n"
          ]
        }
      ],
      "source": [
        "model.config.use_cache = False\n",
        "\n",
        "if torch.__version__ >= \"2\" and sys.platform != \"win32\":\n",
        "    print(\"compiling the model\")\n",
        "    model = torch.compile(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bF5oWKxK1CSL"
      },
      "outputs": [],
      "source": [
        "trainer.train()\n",
        "model.save_pretrained(output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1dRQLMT1CSU"
      },
      "source": [
        "### Load the final checkpoint\n",
        "Now for the moment of truth! Has our work paid off...?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRdVgDTg1CSU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
        "\n",
        "base_model = \"./LLM_fine_tuning/CodeLlama-7b-hf\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model,\n",
        "    load_in_8bit=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76UlHzhy1CSU"
      },
      "source": [
        "To load a fine-tuned Lora/Qlora adapter use PeftModel.from_pretrained. ```output_dir``` should be something containing an adapter_config.json and adapter_model.bin:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQrCR0os1CSU"
      },
      "outputs": [],
      "source": [
        "from peft import PeftModel\n",
        "model = PeftModel.from_pretrained(model, output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roqy_WRi1CSU"
      },
      "source": [
        "Try the same prompt as before:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrCxouNp1CSU"
      },
      "outputs": [],
      "source": [
        "eval_prompt = \"\"\"You are a powerful code generation model. Your job is to complete the below Rust function.\n",
        "/// Walk the repo working directory starting from search_root.\n",
        "/// Return a list of file paths under the search_root, the\n",
        "/// file paths are relative to the working dir root.\n",
        "/// Note that symlinks are ignored because they are difficult to\n",
        "/// deal with: git deals with the symlink file itself without\n",
        "/// following the link.\n",
        "pub fn walk_working_dir(\n",
        "    work_root: impl AsRef<Path>,\n",
        "    search_root: impl AsRef<Path>,\n",
        "    recursive: bool,\n",
        ") -> anyhow::Result<Vec<PathBuf>> {\n",
        "  <FILL_ME>\n",
        "\n",
        "  Ok(result)\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=100)[0], skip_special_tokens=True))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6IcTOCq1CSU"
      },
      "source": [
        "And the model outputs:\n",
        "```\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally merge the adapter and save the model\n",
        "model = model.merge_and_unload()\n",
        "model.save_pretrained(base_model)\n",
        "!cd LLM_fine_tuning && git add . && git commit -m \"Update fine tuned model\" && git push"
      ],
      "metadata": {
        "id": "yHEgbSFyMJTN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ccfdb5b3eab542f99038e3b850902ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b49e9ef3eb3400d9d413e4691158147",
              "IPY_MODEL_c746af61c6fd4e9aa0e8f3a8922c07f5",
              "IPY_MODEL_2bedb7a3425e41e0a8476cfa71b309b2"
            ],
            "layout": "IPY_MODEL_fd03926d82434e82875544ddc0e0fa68"
          }
        },
        "6b49e9ef3eb3400d9d413e4691158147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cba1a51f406c4641a89dd2803a443ed0",
            "placeholder": "​",
            "style": "IPY_MODEL_08d5b480eaf1400bad50e3f85db54f9e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "c746af61c6fd4e9aa0e8f3a8922c07f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_390c417ab953485cbeaef685b963924c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06aa7ea6f81b4403b902ebd381fa8178",
            "value": 2
          }
        },
        "2bedb7a3425e41e0a8476cfa71b309b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ce401bf4e8d42a6bed2554641d7fce5",
            "placeholder": "​",
            "style": "IPY_MODEL_b71f0b968f6a4a7ca0132d30328f6491",
            "value": " 2/2 [00:12&lt;00:00,  5.69s/it]"
          }
        },
        "fd03926d82434e82875544ddc0e0fa68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cba1a51f406c4641a89dd2803a443ed0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08d5b480eaf1400bad50e3f85db54f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "390c417ab953485cbeaef685b963924c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06aa7ea6f81b4403b902ebd381fa8178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ce401bf4e8d42a6bed2554641d7fce5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b71f0b968f6a4a7ca0132d30328f6491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96487863814d486bba165b4ea7d57c93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9153ffc8d412470695671ae4a7b5bc0c",
              "IPY_MODEL_f2d64744eac348798011a02b78c195b6",
              "IPY_MODEL_ac0fe69dcad94153802cbd1240fc7cb7"
            ],
            "layout": "IPY_MODEL_cf67d535aa904052b2129b4485ef2589"
          }
        },
        "9153ffc8d412470695671ae4a7b5bc0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac88bc629fc24c19affc3ca8a77d9101",
            "placeholder": "​",
            "style": "IPY_MODEL_2033e63cb81649c5a5565b674d6561a2",
            "value": "Map: 100%"
          }
        },
        "f2d64744eac348798011a02b78c195b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c64a8d2ad2554571ac81d0b2245282bc",
            "max": 288,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2503e46973644ce0bcc9d1cd3cf90a16",
            "value": 288
          }
        },
        "ac0fe69dcad94153802cbd1240fc7cb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efdddef709bd448294b413b20973ce94",
            "placeholder": "​",
            "style": "IPY_MODEL_5721b429cdbe4a4fabfb4e266d0a5b8a",
            "value": " 288/288 [00:05&lt;00:00, 33.81 examples/s]"
          }
        },
        "cf67d535aa904052b2129b4485ef2589": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac88bc629fc24c19affc3ca8a77d9101": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2033e63cb81649c5a5565b674d6561a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c64a8d2ad2554571ac81d0b2245282bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2503e46973644ce0bcc9d1cd3cf90a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "efdddef709bd448294b413b20973ce94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5721b429cdbe4a4fabfb4e266d0a5b8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10fed5bf8ff34b20943bb858fde7451e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85c6b5d3ed4046b3a30ac675ba36908b",
              "IPY_MODEL_aab05682cf204c828f55e03fca4b7a3a",
              "IPY_MODEL_bf2578d5c6ec4299936e678447f46c69"
            ],
            "layout": "IPY_MODEL_e9c99387b0914bfdaad0fab70ec5f580"
          }
        },
        "85c6b5d3ed4046b3a30ac675ba36908b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_412309cc0a224be5b51a54d88d74c492",
            "placeholder": "​",
            "style": "IPY_MODEL_30386ef794ec43a1ae06688a1ffbb0f2",
            "value": "Map: 100%"
          }
        },
        "aab05682cf204c828f55e03fca4b7a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09a769a9822a42f7ae2664a1d80a8905",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c039af9f6b4d4fefb074b7da2566174c",
            "value": 32
          }
        },
        "bf2578d5c6ec4299936e678447f46c69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b8c59b0b94049e298ec744f9894981a",
            "placeholder": "​",
            "style": "IPY_MODEL_e37154250e974e1e880f85da0665e5e8",
            "value": " 32/32 [00:00&lt;00:00, 154.92 examples/s]"
          }
        },
        "e9c99387b0914bfdaad0fab70ec5f580": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "412309cc0a224be5b51a54d88d74c492": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30386ef794ec43a1ae06688a1ffbb0f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09a769a9822a42f7ae2664a1d80a8905": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c039af9f6b4d4fefb074b7da2566174c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b8c59b0b94049e298ec744f9894981a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e37154250e974e1e880f85da0665e5e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}